{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0692944",
   "metadata": {},
   "source": [
    "## Q 2a) Fine-tune the pre-trained BERT model for the UPOS prediction task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59bc9ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: conllu in c:\\users\\abhil\\anaconda3\\lib\\site-packages (4.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install conllu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9903800a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\abhil\\anaconda3\\lib\\site-packages (1.13.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from torch) (4.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12c28a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval in c:\\users\\abhil\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from seqeval) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from seqeval) (1.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e49534f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1659"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import conllu\n",
    "from conllu import parse\n",
    "\n",
    "data_file = open(\"hi_hdtb-ud-dev.conllu\", \"r\", encoding=\"utf-8\").read()\n",
    "sentences = parse(data_file)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ea3578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sentence.serialize() for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1eb68736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Split size may be adjusted here\n",
    "train, test = train_test_split(sentences,test_size=0.20)\n",
    "train, val = train_test_split(train,test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "09668853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1194, 133, 332)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train),len(val),len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9693bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "## Create directory data/ if does not exist\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "    \n",
    "for l,s in zip([train,val,test],['train','validation','test']):\n",
    "    with open(f'data/{s}.conllu','w',encoding='utf-8') as fp:\n",
    "        fp.write(''.join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e75a478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\abhil\\anaconda3\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from datasets) (2022.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from datasets) (1.21.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from datasets) (1.4.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from datasets) (3.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from datasets) (0.10.1)\n",
      "Requirement already satisfied: dill<0.3.6 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from datasets) (10.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (5.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a9eb0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3a4583a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset conllu_indic (C:/Users/abhil/.cache/huggingface/datasets/conllu_indic/conlluindic/1.0.0/50260ca812993370c93c5949d08ad1fb388e0fced25f584d6ede7b09423bc32c)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403263e4d65b4c3e8dd52a66b4983c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'lemmas', 'upos_tags'],\n",
       "        num_rows: 1194\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'lemmas', 'upos_tags'],\n",
       "        num_rows: 133\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'lemmas', 'upos_tags'],\n",
       "        num_rows: 332\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('ConlluIndic.py')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "01e9ccad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\abhil\\anaconda3\\lib\\site-packages (0.1.97)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f0eea0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\abhil\\anaconda3\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: requests in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from transformers) (0.13.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhil\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3740a3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file config.json from cache at C:\\Users\\abhil/.cache\\huggingface\\hub\\models--ai4bharat--indic-bert\\snapshots\\4842dd258ecc0546f0d660b76a3b22a9c632f401\\config.json\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading file spiece.model from cache at C:\\Users\\abhil/.cache\\huggingface\\hub\\models--ai4bharat--indic-bert\\snapshots\\4842dd258ecc0546f0d660b76a3b22a9c632f401\\spiece.model\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\abhil/.cache\\huggingface\\hub\\models--ai4bharat--indic-bert\\snapshots\\4842dd258ecc0546f0d660b76a3b22a9c632f401\\config.json\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\abhil/.cache\\huggingface\\hub\\models--ai4bharat--indic-bert\\snapshots\\4842dd258ecc0546f0d660b76a3b22a9c632f401\\config.json\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = 'ai4bharat/indic-bert'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e887c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            #if label % 2 == 1:\n",
    "            #    label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b3ba97a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"upos_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fc3b585c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/abhil/.cache/huggingface/datasets/conllu_indic/conlluindic/1.0.0/50260ca812993370c93c5949d08ad1fb388e0fced25f584d6ede7b09423bc32c\\cache-fa75edc484da9b39.arrow\n",
      "Loading cached processed dataset at C:/Users/abhil/.cache/huggingface/datasets/conllu_indic/conlluindic/1.0.0/50260ca812993370c93c5949d08ad1fb388e0fced25f584d6ede7b09423bc32c\\cache-780f601eaf1c85b7.arrow\n",
      "Loading cached processed dataset at C:/Users/abhil/.cache/huggingface/datasets/conllu_indic/conlluindic/1.0.0/50260ca812993370c93c5949d08ad1fb388e0fced25f584d6ede7b09423bc32c\\cache-016a86a47ba84b80.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c165c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, TrainingArguments, Trainer\n",
    "from datasets import load_metric, load_from_disk, load_dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d694e948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file config.json from cache at C:\\Users\\abhil/.cache\\huggingface\\hub\\models--ai4bharat--indic-bert\\snapshots\\4842dd258ecc0546f0d660b76a3b22a9c632f401\\config.json\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading file spiece.model from cache at C:\\Users\\abhil/.cache\\huggingface\\hub\\models--ai4bharat--indic-bert\\snapshots\\4842dd258ecc0546f0d660b76a3b22a9c632f401\\spiece.model\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\abhil/.cache\\huggingface\\hub\\models--ai4bharat--indic-bert\\snapshots\\4842dd258ecc0546f0d660b76a3b22a9c632f401\\config.json\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\abhil/.cache\\huggingface\\hub\\models--ai4bharat--indic-bert\\snapshots\\4842dd258ecc0546f0d660b76a3b22a9c632f401\\config.json\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "Found cached dataset conllu_indic (C:/Users/abhil/.cache/huggingface/datasets/conllu_indic/conlluindic/1.0.0/50260ca812993370c93c5949d08ad1fb388e0fced25f584d6ede7b09423bc32c)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424d95bb275d4292aae2b629eaec2f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\abhil/.cache\\huggingface\\hub\\models--ai4bharat--indic-bert\\snapshots\\4842dd258ecc0546f0d660b76a3b22a9c632f401\\config.json\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"ADJ\",\n",
      "    \"1\": \"ADP\",\n",
      "    \"10\": \"PRON\",\n",
      "    \"11\": \"PROPN\",\n",
      "    \"12\": \"PUNCT\",\n",
      "    \"13\": \"SCONJ\",\n",
      "    \"14\": \"SYM\",\n",
      "    \"15\": \"VERB\",\n",
      "    \"16\": \"X\",\n",
      "    \"17\": \"_\",\n",
      "    \"2\": \"ADV\",\n",
      "    \"3\": \"AUX\",\n",
      "    \"4\": \"CCONJ\",\n",
      "    \"5\": \"DET\",\n",
      "    \"6\": \"INTJ\",\n",
      "    \"7\": \"NOUN\",\n",
      "    \"8\": \"NUM\",\n",
      "    \"9\": \"PART\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"ADJ\": \"0\",\n",
      "    \"ADP\": \"1\",\n",
      "    \"ADV\": \"2\",\n",
      "    \"AUX\": \"3\",\n",
      "    \"CCONJ\": \"4\",\n",
      "    \"DET\": \"5\",\n",
      "    \"INTJ\": \"6\",\n",
      "    \"NOUN\": \"7\",\n",
      "    \"NUM\": \"8\",\n",
      "    \"PART\": \"9\",\n",
      "    \"PRON\": \"10\",\n",
      "    \"PROPN\": \"11\",\n",
      "    \"PUNCT\": \"12\",\n",
      "    \"SCONJ\": \"13\",\n",
      "    \"SYM\": \"14\",\n",
      "    \"VERB\": \"15\",\n",
      "    \"X\": \"16\",\n",
      "    \"_\": \"17\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\abhil/.cache\\huggingface\\hub\\models--ai4bharat--indic-bert\\snapshots\\4842dd258ecc0546f0d660b76a3b22a9c632f401\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertForTokenClassification: ['predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.LayerNorm.weight', 'predictions.dense.bias', 'sop_classifier.classifier.weight', 'predictions.decoder.weight', 'sop_classifier.classifier.bias', 'predictions.decoder.bias', 'predictions.bias']\n",
      "- This IS expected if you are initializing AlbertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = 'ai4bharat/indic-bert'\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenized_datasets = load_from_disk(r'C:\\Users\\abhil\\tokenized_datasets\\tokenized_datasets')\n",
    "\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "metric = load_metric('seqeval')\n",
    "\n",
    "\n",
    "\n",
    "dataset = load_dataset('ConlluIndic.py')\n",
    "\n",
    "upos_feature = dataset['train'].features['upos_tags']\n",
    "label_names = upos_feature.feature.names\n",
    "\n",
    "\n",
    "\n",
    "id2label = {str(i): label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint,id2label=id2label,label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4499c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c1ed7790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "args = TrainingArguments(\n",
    "    output_dir=f\"model/upos\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    #fp16= True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    #eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fd74169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1194\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 10\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 10\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1200\n",
      "  Number of trainable parameters = 32866834\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1200/1200 56:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.608646</td>\n",
       "      <td>0.860224</td>\n",
       "      <td>0.861296</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.892724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.587595</td>\n",
       "      <td>0.840503</td>\n",
       "      <td>0.860050</td>\n",
       "      <td>0.850164</td>\n",
       "      <td>0.882463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.507979</td>\n",
       "      <td>0.864809</td>\n",
       "      <td>0.863372</td>\n",
       "      <td>0.864090</td>\n",
       "      <td>0.892491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.566897</td>\n",
       "      <td>0.867188</td>\n",
       "      <td>0.875831</td>\n",
       "      <td>0.871488</td>\n",
       "      <td>0.897854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.583324</td>\n",
       "      <td>0.869979</td>\n",
       "      <td>0.872508</td>\n",
       "      <td>0.871242</td>\n",
       "      <td>0.902519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.599047</td>\n",
       "      <td>0.880972</td>\n",
       "      <td>0.888289</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.905317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.609163</td>\n",
       "      <td>0.886092</td>\n",
       "      <td>0.891611</td>\n",
       "      <td>0.888843</td>\n",
       "      <td>0.907882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.575716</td>\n",
       "      <td>0.887289</td>\n",
       "      <td>0.895764</td>\n",
       "      <td>0.891507</td>\n",
       "      <td>0.913246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.584627</td>\n",
       "      <td>0.887747</td>\n",
       "      <td>0.896595</td>\n",
       "      <td>0.892149</td>\n",
       "      <td>0.913246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.590251</td>\n",
       "      <td>0.888158</td>\n",
       "      <td>0.897010</td>\n",
       "      <td>0.892562</td>\n",
       "      <td>0.913246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 133\n",
      "  Batch size = 10\n",
      "Saving model checkpoint to model/upos\\checkpoint-120\n",
      "Configuration saved in model/upos\\checkpoint-120\\config.json\n",
      "Model weights saved in model/upos\\checkpoint-120\\pytorch_model.bin\n",
      "tokenizer config file saved in model/upos\\checkpoint-120\\tokenizer_config.json\n",
      "Special tokens file saved in model/upos\\checkpoint-120\\special_tokens_map.json\n",
      "Deleting older checkpoint [model\\upos\\checkpoint-1200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 133\n",
      "  Batch size = 10\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Saving model checkpoint to model/upos\\checkpoint-240\n",
      "Configuration saved in model/upos\\checkpoint-240\\config.json\n",
      "Model weights saved in model/upos\\checkpoint-240\\pytorch_model.bin\n",
      "tokenizer config file saved in model/upos\\checkpoint-240\\tokenizer_config.json\n",
      "Special tokens file saved in model/upos\\checkpoint-240\\special_tokens_map.json\n",
      "Deleting older checkpoint [model\\upos\\checkpoint-120] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 133\n",
      "  Batch size = 10\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Saving model checkpoint to model/upos\\checkpoint-360\n",
      "Configuration saved in model/upos\\checkpoint-360\\config.json\n",
      "Model weights saved in model/upos\\checkpoint-360\\pytorch_model.bin\n",
      "tokenizer config file saved in model/upos\\checkpoint-360\\tokenizer_config.json\n",
      "Special tokens file saved in model/upos\\checkpoint-360\\special_tokens_map.json\n",
      "Deleting older checkpoint [model\\upos\\checkpoint-240] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 133\n",
      "  Batch size = 10\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to model/upos\\checkpoint-480\n",
      "Configuration saved in model/upos\\checkpoint-480\\config.json\n",
      "Model weights saved in model/upos\\checkpoint-480\\pytorch_model.bin\n",
      "tokenizer config file saved in model/upos\\checkpoint-480\\tokenizer_config.json\n",
      "Special tokens file saved in model/upos\\checkpoint-480\\special_tokens_map.json\n",
      "Deleting older checkpoint [model\\upos\\checkpoint-360] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 133\n",
      "  Batch size = 10\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Saving model checkpoint to model/upos\\checkpoint-600\n",
      "Configuration saved in model/upos\\checkpoint-600\\config.json\n",
      "Model weights saved in model/upos\\checkpoint-600\\pytorch_model.bin\n",
      "tokenizer config file saved in model/upos\\checkpoint-600\\tokenizer_config.json\n",
      "Special tokens file saved in model/upos\\checkpoint-600\\special_tokens_map.json\n",
      "Deleting older checkpoint [model\\upos\\checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 133\n",
      "  Batch size = 10\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Saving model checkpoint to model/upos\\checkpoint-720\n",
      "Configuration saved in model/upos\\checkpoint-720\\config.json\n",
      "Model weights saved in model/upos\\checkpoint-720\\pytorch_model.bin\n",
      "tokenizer config file saved in model/upos\\checkpoint-720\\tokenizer_config.json\n",
      "Special tokens file saved in model/upos\\checkpoint-720\\special_tokens_map.json\n",
      "Deleting older checkpoint [model\\upos\\checkpoint-600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 133\n",
      "  Batch size = 10\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to model/upos\\checkpoint-840\n",
      "Configuration saved in model/upos\\checkpoint-840\\config.json\n",
      "Model weights saved in model/upos\\checkpoint-840\\pytorch_model.bin\n",
      "tokenizer config file saved in model/upos\\checkpoint-840\\tokenizer_config.json\n",
      "Special tokens file saved in model/upos\\checkpoint-840\\special_tokens_map.json\n",
      "Deleting older checkpoint [model\\upos\\checkpoint-720] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 133\n",
      "  Batch size = 10\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Saving model checkpoint to model/upos\\checkpoint-960\n",
      "Configuration saved in model/upos\\checkpoint-960\\config.json\n",
      "Model weights saved in model/upos\\checkpoint-960\\pytorch_model.bin\n",
      "tokenizer config file saved in model/upos\\checkpoint-960\\tokenizer_config.json\n",
      "Special tokens file saved in model/upos\\checkpoint-960\\special_tokens_map.json\n",
      "Deleting older checkpoint [model\\upos\\checkpoint-840] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 133\n",
      "  Batch size = 10\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Saving model checkpoint to model/upos\\checkpoint-1080\n",
      "Configuration saved in model/upos\\checkpoint-1080\\config.json\n",
      "Model weights saved in model/upos\\checkpoint-1080\\pytorch_model.bin\n",
      "tokenizer config file saved in model/upos\\checkpoint-1080\\tokenizer_config.json\n",
      "Special tokens file saved in model/upos\\checkpoint-1080\\special_tokens_map.json\n",
      "Deleting older checkpoint [model\\upos\\checkpoint-960] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 133\n",
      "  Batch size = 10\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to model/upos\\checkpoint-1200\n",
      "Configuration saved in model/upos\\checkpoint-1200\\config.json\n",
      "Model weights saved in model/upos\\checkpoint-1200\\pytorch_model.bin\n",
      "tokenizer config file saved in model/upos\\checkpoint-1200\\tokenizer_config.json\n",
      "Special tokens file saved in model/upos\\checkpoint-1200\\special_tokens_map.json\n",
      "Deleting older checkpoint [model\\upos\\checkpoint-1080] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1200, training_loss=0.02337848622351885, metrics={'train_runtime': 3397.9791, 'train_samples_per_second': 3.514, 'train_steps_per_second': 0.353, 'total_flos': 32022918557328.0, 'train_loss': 0.02337848622351885, 'epoch': 10.0})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4c082c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 133\n",
      "  Batch size = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5902513861656189,\n",
       " 'eval_precision': 0.8881578947368421,\n",
       " 'eval_recall': 0.8970099667774086,\n",
       " 'eval_f1': 0.8925619834710744,\n",
       " 'eval_accuracy': 0.9132462686567164,\n",
       " 'eval_runtime': 13.3108,\n",
       " 'eval_samples_per_second': 9.992,\n",
       " 'eval_steps_per_second': 1.052}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ea780611",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 332\n",
      "  Batch size = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='81' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 55:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhil\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: X seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.627139687538147,\n",
       " 'eval_precision': 0.8841870824053452,\n",
       " 'eval_recall': 0.898771021992238,\n",
       " 'eval_f1': 0.8914194065757818,\n",
       " 'eval_accuracy': 0.9079005184989893,\n",
       " 'eval_runtime': 27.526,\n",
       " 'eval_samples_per_second': 12.061,\n",
       " 'eval_steps_per_second': 1.235}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ba7bb",
   "metadata": {},
   "source": [
    "## 2)b) The micro precison is 0.8881578947368421.\n",
    "##         The micro recall is 0.8970099667774086. \n",
    "##         The micro F1 score is 0.8925619834710744.\n",
    "##         The macro Precision is 0.886172488565.\n",
    "##         The macro recall is 0.89789049438.\n",
    "##          The macro F1 score is 0.891990695023.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
